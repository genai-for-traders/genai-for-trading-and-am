{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0STeusoHZDDG"
   },
   "source": [
    "# Customizing Your LLM to Your Needs: Fine-Tuning Llama 3.1 Using QLoRA\n",
    "\n",
    "As a practical use case of how we can adapt an LLM to our own needs, we will simulate a situation where we have access to an LLM and want to adapt it to better respond to some private documentation, specifically, answering domain-specific questions.\n",
    "\n",
    "As mentioned in Chapter 10 of the book, one way to customize an LLM to work with your own data is through fine-tuning, also known as post-training.  In this notebook, as a practical example, we will **fine-tune Metaâ€™s Llama 3.1** to answer **finance-related questions**!\n",
    "\n",
    "For more details about fine-tuning and efficient inference, we recommend reviewing Chapter 10.  If needed, for implementation details, we invite you to revisit the previous tutorials on Hugging Face, dataset handling, and model fine-tuning before on the book repository diving into this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeqlVbIfZDDH"
   },
   "source": [
    "## Install packages\n",
    "\n",
    "We will use the [Unsloth](https://github.com/unslothai/unsloth) library, which extends Hugging Face's transformers to make finetuning faster and less resource-intensive.\n",
    "\n",
    "Let's install Unsloth, Flash Attention (via Xformers), and other necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3LFy2M9Ztb_j",
    "outputId": "7bcc86dc-759e-4646-f0ac-16b72b499ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-32m5_kpx/unsloth_2239a5cbf8af4e709fcbae5e624c59dd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-32m5_kpx/unsloth_2239a5cbf8af4e709fcbae5e624c59dd\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 5177df5f784cd3e1b0aa3db8d6eb6945b49579ae\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting unsloth_zoo>=2025.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading unsloth_zoo-2025.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
      "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.51.3)\n",
      "Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
      "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.30.2)\n",
      "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.4.1-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for unsloth: filename=unsloth-2025.4.1-py3-none-any.whl size=199307 sha256=0595dcaad15ffc4f6cab14b36e96d49a00c7f9a4df9af38384ca165b0947407d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-u3v08npe/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
      "Successfully built unsloth\n",
      "Installing collected packages: xxhash, unsloth, shtab, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf_transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.4\n",
      "    Uninstalling protobuf-5.29.4:\n",
      "      Successfully uninstalled protobuf-5.29.4\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 hf_transfer-0.1.9 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.2 trl-0.15.2 tyro-0.9.19 unsloth-2025.4.1 unsloth_zoo-2025.4.1 xxhash-3.5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "8aac8dd411654bfba9ad6e6114584b13",
       "pip_warning": {
        "packages": [
         "google"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xformers\n",
      "  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
      "Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xformers\n",
      "Successfully installed xformers-0.0.30\n",
      "Collecting datasets==3.5.0\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.0\n",
      "    Uninstalling fsspec-2025.3.0:\n",
      "      Successfully uninstalled fsspec-2025.3.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.5.1\n",
      "    Uninstalling datasets-3.5.1:\n",
      "      Successfully uninstalled datasets-3.5.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.0 fsspec-2024.12.0\n"
     ]
    }
   ],
   "source": [
    "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "!pip install datasets==3.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i9fIQrjZDDI"
   },
   "source": [
    "## Model: Llama 3.1 8B\n",
    "\n",
    "\n",
    "For this tutorial, we will use [Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/) with 8 billion parameters, commonly referred to as Llama 3.1 8B. The choice of model size is mainly based on the free computational resources available on Google Colab for experimentation.\n",
    "\n",
    "However, working with thei model in half precision (float16) would require about 16GB of VRAM, which matches the maximum available memory in Colab at the time of writing. If we try to fine-tune the model with this setup, it would likely result in out-of-memory  errors.\n",
    "\n",
    "To solve this, we will use a quantized 4-bit precision version of the Llama 3.1 8B model, published by [unsloth](https://huggingface.co/unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit). Quantization reduces the model size and memory requirements significantly, allowing us to fine-tune the LLM with fewer resources.\n",
    "\n",
    "More details about quantization can be found in Chapter 10 of the book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fohoIULAZDDI"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "cd23cd474239493398442f8fac75b060",
      "a1a0804f50e6400fb34e5fc6e9eae304",
      "e0d0f2e11a274127a51bc069be9e365c",
      "24fe11f353034e2ba07402b21b265268",
      "be8c0380d4f4456b8045bc9d4d74e4b2",
      "af758b172e074547a7089f3ff1a71203",
      "0d4e47d0322d4218a25e72b576b6e4a5",
      "302534b2a6d54775a2aa524c60fe4b69",
      "8057c8b3167a4956b8d6088c1b4775f6",
      "5e751c8993f74857b6fa1cca9632f025",
      "eaaf2aec0bf94b43abf99fa8feb665b0",
      "716f38fe044940a7bc0146646340cd09",
      "2edc311e36eb4962a73adceb5d96aeef",
      "09244a227f5040d98282357b8e695398",
      "f5fa307bb59f4fe18cfdb4885bd1192e",
      "ee9d5a79fcba4c72890fa5a2d21eea05",
      "970f0c6156054d63bee2216aaf255822",
      "e94323a5530246cf92f65969c5a05ad1",
      "9e58c61802534872a027b393aa48fee1",
      "fc04d72a06e94a398ef4211305fda73d",
      "f7f5a98138f8491dbbdee019a8acee86",
      "6a8eff44f5d34ec2b1a89f7a6a9af744",
      "1d28ac298eb34820a6a5528d5562a0b4",
      "7a54b52a20b842729eee15feea3d6ca6",
      "d38d90835ac84bfca1938a51439cb39c",
      "f4fc42dc50f14a5198b3c22e8b6fba8c",
      "18039f635cee4d6ab4d2ad461f5f019a",
      "67ca422950644ffb81f656a433151fd1",
      "4ce1a95c4b3d48448c26ae842b181c93",
      "18e59c688b8147cab4ca31a228d7cb13",
      "63b0e142610646bfa087a7bbc38e4f9d",
      "201063cef5284bbf9a19dd57bfb50b41",
      "0d03f6d34e7545e981df082914d8918b",
      "8eefa8ec13ab4ece9807b2dc9d1af972",
      "7bed7255c4c6413fbc48dcba1754a353",
      "e94623aee4214669aebcc28be16fab8c",
      "fbb7747005324efaa132915278dc7147",
      "a80d587860f84d4a87a7dfb2135adba8",
      "ccfaa192aea242c284eeb8aac073beb5",
      "19928a542a094b07beb7ead103d7f133",
      "8ee8332c42a34c5d96fc433242557353",
      "c006f3932f954d569a5a771889b9984f",
      "040f23f74b004566bf148e9875fb6d81",
      "c968b253e46c4570b678e8f7b8d078c9",
      "6cf52c006304496bb2137891e4048f91",
      "0256e99c93e144c680dfee592f427831",
      "7c75cb8878c64ee9b9b56b7ebb0d9468",
      "7650832a23874b4d954cd9faf6476a2c",
      "8cae1370671e4dadb2ecd85c27693d54",
      "0dc63455552b47d78d69655937614a8f",
      "9a05882cdb6d43ca96296b17f305b8b7",
      "eb6f63b5cae34dc0aef20fc773ea6891",
      "a1007fe58c2d40d0b2a5af5fb34860d1",
      "5ca1fd89240d4effb9f0eaab22460f89",
      "40cf7ea4169e45d88a705987ad77da4a"
     ]
    },
    "id": "QueeSe7YZDDI",
    "outputId": "9707256e-3854-4423-ca3c-e7838871c109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
      "    Python  3.11.12 (you have 3.11.12)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd23cd474239493398442f8fac75b060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716f38fe044940a7bc0146646340cd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d28ac298eb34820a6a5528d5562a0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eefa8ec13ab4ece9807b2dc9d1af972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf52c006304496bb2137891e4048f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"model_name\": 'unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit',\n",
    "    'max_seq_length': 2048 * 4,\n",
    "}\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "      model_name=MODEL_CONFIG['model_name'],\n",
    "      max_seq_length=MODEL_CONFIG['max_seq_length'],\n",
    "      load_in_4bit=True,\n",
    "      dtype=None,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBSUI6BcZDDI"
   },
   "source": [
    "## Data\n",
    "\n",
    "We will use the [finance-alpaca](https://huggingface.co/datasets/gbharti/finance-alpaca) dataset, a Question-Answer (QA) set combining:\n",
    "\n",
    "- Stanfordâ€™s Alpaca dataset\n",
    "- FiQA (Financial Question Answering) dataset\n",
    "- 1,300+ custom QA pairs generated via GPT-3.5\n",
    "\n",
    "This dataset contains 68,912 examples and follows the typical Alpaca format `(instruction, input, output, text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YXkQTUdPuS-L"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datasets import load_dataset\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "ba6f194b6eb84cddac62bdee1453cf16",
      "9f713aea19e24f13acb87c23e0158aa6",
      "b434b128caac4209b148c3ffa37f635a",
      "30698b2252144044b09389ebb639b958",
      "b946a5a292fd470c89b9b77e9a404eec",
      "d7192ae724004a6c897e6abc069033b5",
      "ea33da685208443fa11f34964ee53d6c",
      "652612ffc0234a27a3387c6aa5ed256a",
      "97cae741496c472b81b5ab9e59d5f0cd",
      "09752b9379584ac3960ff9e4a47bc007",
      "6ce144c8c42d4a10879b02f956cbbf1a",
      "05b87199704242d7831a1f48e543fd2d",
      "32a124605c05408b8f77a7d6f6173599",
      "c8bc762b2c454bc0906d377f10995e5a",
      "527a4a963e3c454395bded8a6e20f6c3",
      "d075a915498d49dc93250e9ac4e899ef",
      "e2fcf41ead40414ca81b1745a2a3a9d0",
      "e55cd439db154843a160e6985bd0b0ef",
      "5f03b91530ed4965ab3942af9e229032",
      "f15ed13adff24568a693643ba1a36090",
      "e3053b25a4724537adf041bfe16e6e7f",
      "c9933a3c158f4989acec10494e5ca626",
      "3e3cde2fc16a45bebfeeea2b0cda476e",
      "76228fc50f6945fb930761a014181a28",
      "e3820ba468c840ce94d51e62b3fbe576",
      "9503d432c6194ba5be92dacec95e8cd0",
      "1d60b3d6cfaa46af9126a952f74207e6",
      "52f263232e654c4eb0df044dd49f2cf8",
      "17c1a0370f734e16b54eccbd70f865e4",
      "a287f3b618e44da6841167da79aadf6c",
      "eda93e6ed8ec42bf8fdd63de96e08e1e",
      "cef6154a875d4cf8b9bac78d7a7a9d68",
      "18f3e701b5a84513a08724d1d0efd65e"
     ]
    },
    "id": "p-iUAL6WvDRH",
    "outputId": "86903ade-1a46-41bc-f0e0-0ca6dc431eed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6f194b6eb84cddac62bdee1453cf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b87199704242d7831a1f48e543fd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaned_date.json:   0%|          | 0.00/42.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3cde2fc16a45bebfeeea2b0cda476e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the \"finance-alpaca\" dataset from Hugging Face.\n",
    "data = load_dataset(\"gbharti/finance-alpaca\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WD1zfYX6CI0",
    "outputId": "1b67a6a7-16cc-4348-acb3-1ce4e0b78207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 68912\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPgA2AlfZDDJ",
    "outputId": "5a5de28e-c68e-40c9-af50-cd986a1c9aca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'For a car, what scams can be plotted with 0% financing vs rebate?',\n",
       " 'input': '',\n",
       " 'output': \"The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.\",\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first data sample\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXzdkCLMZDDJ"
   },
   "source": [
    "The `input` and `text` are empty, the `instruction` field contains the question, and `output` contains the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQv2k0qpvuHD",
    "outputId": "9f59c4a8-8ced-4b04-e51d-654fed3a5f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '',\n",
      " 'instruction': 'For a car, what scams can be plotted with 0% financing vs '\n",
      "                'rebate?',\n",
      " 'output': 'The car deal makes money 3 ways. If you pay in one lump payment. '\n",
      "           'If the payment is greater than what they paid for the car, plus '\n",
      "           'their expenses, they make a profit. They loan you the money. You '\n",
      "           'make payments over months or years, if the total amount you pay is '\n",
      "           'greater than what they paid for the car, plus their expenses, plus '\n",
      "           'their finance expenses they make money. Of course the money takes '\n",
      "           'years to come in, or they sell your loan to another business to '\n",
      "           'get the money faster but in a smaller amount. You trade in a car '\n",
      "           'and they sell it at a profit. Of course that new transaction could '\n",
      "           'be a lump sum or a loan on the used car... They or course make '\n",
      "           'money if you bring the car back for maintenance, or you buy lots '\n",
      "           'of expensive dealer options. Some dealers wave two deals in front '\n",
      "           'of you: get a 0% interest loan. These tend to be shorter 12 months '\n",
      "           'vs 36,48,60 or even 72 months. The shorter length makes it harder '\n",
      "           \"for many to afford. If you can't swing the 12 large payments they \"\n",
      "           'offer you at x% loan for y years that keeps the payments in your '\n",
      "           'budget. pay cash and get a rebate. If you take the rebate you '\n",
      "           \"can't get the 0% loan. If you take the 0% loan you can't get the \"\n",
      "           'rebate. The price you negotiate minus the rebate is enough to make '\n",
      "           'a profit. The key is not letting them know which offer you are '\n",
      "           \"interested in. Don't even mention a trade in until the price of \"\n",
      "           'the new car has been finalized. Otherwise they will adjust the '\n",
      "           'price, rebate, interest rate, length of loan,  and trade-in value '\n",
      "           'to maximize their profit. The suggestion of running the numbers '\n",
      "           'through a spreadsheet is a good one. If you get a loan for 2% from '\n",
      "           'your bank/credit union for 3 years and the rebate from the dealer, '\n",
      "           'it will cost less in total than the 0% loan from the dealer. The '\n",
      "           'key is to get the loan approved by the bank/credit union before '\n",
      "           'meeting with the dealer. The money from the bank looks like cash '\n",
      "           'to the dealer.',\n",
      " 'text': ''}\n",
      "{'input': '',\n",
      " 'instruction': 'Why does it matter if a Central Bank has a negative rather '\n",
      "                'than 0% interest rate?',\n",
      " 'output': 'That is kind of the point, one of the hopes is that it '\n",
      "           'incentivizes banks to stop storing money and start injecting it '\n",
      "           'into the economy themselves. Compared to the European Central Bank '\n",
      "           'investing directly into the economy the way the US central bank '\n",
      "           'has been doing. (The Federal Reserve buying mortgage backed '\n",
      "           'securities) On a country level, individual European countries have '\n",
      "           'tried this before in recent times with no noticeable effect.',\n",
      " 'text': ''}\n",
      "{'input': '',\n",
      " 'instruction': 'Where should I be investing my money?',\n",
      " 'output': 'Pay off your debt.  As you witnessed, no \"investment\" % is '\n",
      "           'guaranteed.  But your debt payments are... so if you have cash, '\n",
      "           'the best way to \"invest\" it is to pay off your debt.  Since your '\n",
      "           \"car is depreciating while your house may be appreciating (don't \"\n",
      "           \"know but it's possible) you should pay off your car loan first.  \"\n",
      "           \"You're losing money in more than one way on that investment.\",\n",
      " 'text': ''}\n",
      "{'input': '',\n",
      " 'instruction': 'Specifically when do options expire?',\n",
      " 'output': 'Equity options, at least those traded in the American exchanges, '\n",
      "           'actually expire the Saturday after the 3rd Friday of the month.  '\n",
      "           'However, the choice to trade or exercise the options must be '\n",
      "           'specified by the 3rd Friday. This is outlined by the CBOE, who '\n",
      "           'oversees the exchange of equity options.  Their FAQ regarding '\n",
      "           'option expiration can be found at '\n",
      "           'http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.',\n",
      " 'text': ''}\n",
      "{'input': '',\n",
      " 'instruction': 'Negative Balance from Automatic Options Exercise. What to do?',\n",
      " 'output': 'Automatic exercisions can be extremely risky, and the closer to '\n",
      "           'the money the options are, the riskier their exercisions are. It '\n",
      "           'is unlikely that the entire account has negative equity since a '\n",
      "           'responsible broker would forcibly close all positions and pursue '\n",
      "           'the holder for the balance of the debt to reduce solvency risk.  '\n",
      "           'Since the broker has automatically exercised a near the money '\n",
      "           \"option, it's solvency policy is already risky. Regardless of \"\n",
      "           'whether there is negative equity or simply a liability, the least '\n",
      "           'risky course of action is to sell enough of the underlying to '\n",
      "           'satisfy the loan by closing all other positions if necessary as '\n",
      "           'soon as possible. If there is a negative equity after trying to '\n",
      "           'satisfy the loan, the account will need to be funded for the '\n",
      "           'balance of the loan to pay for purchases of the underlying to '\n",
      "           'fully satisfy the loan. Since the underlying can move in such a '\n",
      "           'way to cause this loan to increase, the account should also be '\n",
      "           'funded as soon as possible if necessary. Accounts after exercise '\n",
      "           'For deep in the money exercised options, a call turns into a long '\n",
      "           'underlying on margin while a put turns into a short underlying. '\n",
      "           'The next decision should be based upon risk and position '\n",
      "           'selection.  First, if the position is no longer attractive, it '\n",
      "           \"should be closed.  Since it's deep in the money, simply closing \"\n",
      "           'out the exposure to the underlying should extinguish the liability '\n",
      "           'as cash is not marginable, so the cash received from the closing '\n",
      "           'out of the position will repay any margin debt. If the position in '\n",
      "           'the underlying is still attractive then the liability should be '\n",
      "           \"managed according to one's liability policy and of course to \"\n",
      "           'margin limits. In a margin account, closing the underlying '\n",
      "           'positions on the same day as the exercise will only be considered '\n",
      "           'a day trade.  If the positions are closed on any business day '\n",
      "           'after the exercision, there will be no penalty or restriction. '\n",
      "           'Cash option accounts While this is possible, many brokers force an '\n",
      "           'upgrade to a margin account, and the ShareBuilder Options Account '\n",
      "           'Agreement seems ambiguous, but their options trading page implies '\n",
      "           'the upgrade. In a cash account, equities are not marginable, so '\n",
      "           'any margin will trigger a margin call.  If the margin debt did not '\n",
      "           'trigger a margin call then it is unlikely that it is a cash '\n",
      "           'account as margin for any security in a cash account except for '\n",
      "           'certain options trades is 100%. Equities are convertible to cash '\n",
      "           'presumably at the bid, so during a call exercise, the exercisor or '\n",
      "           \"exercisor's broker pays cash for the underlying at the exercise \"\n",
      "           'price, and any deficit is financed with debt, thus underlying can '\n",
      "           'be sold to satisfy that debt or be sold for cash as one normally '\n",
      "           'would. To preempt a forced exercise as a call holder, one could '\n",
      "           'short the underlying, but this will be more expensive, and since '\n",
      "           'probably no broker allows shorting against the box because of its '\n",
      "           'intended use to circumvent capital gains taxes by fraud.  The '\n",
      "           'least expensive way to trade out of options positions is to close '\n",
      "           'them themselves rather than take delivery.',\n",
      " 'text': ''}\n"
     ]
    }
   ],
   "source": [
    "# the first 5 samples from the dataset\n",
    "for i in range(5):\n",
    "    pprint.pprint(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_SeoR8gM1FA"
   },
   "source": [
    "## Data Processing: Chat template\n",
    "\n",
    "Since we want to create a chatbot that can answer finance questions, we must organize the input (questions) and output (answers) into a specific structure that the model was trained to recognize.\n",
    "\n",
    "For example, a simple conversation looks like this:\n",
    "\n",
    "```\n",
    "User: \"Who is the greatest macro trader of all time?\"\n",
    "Assistant: \"George Soros\"\n",
    "```\n",
    "\n",
    "This Q&A sample was answered by ChatGPT-4o. The **Instruct** version of Llama 3.1 was fine-tuned on instructions datasets with the same format as ours, and during its training, Meta used a specific way to organize conversations, which we will use in this notebook. You can read more about the prompt format at [Model Cards & Prompt formats\n",
    "Llama 3.1](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoA7cv_oZDDJ"
   },
   "source": [
    "We will first create a conversation, which is simply a list of dictionaries. Each dictionary will have two keys:\n",
    "\n",
    "1. `role`: indicates who is speaking â€” user, assistant, system, etc.)\n",
    "2. `content`: the actual text of the message\n",
    "\n",
    "Then we use the `.apply_chat_template` method to convert the conversation into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HM5_7vjo4jEG"
   },
   "outputs": [],
   "source": [
    "test_conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is the greatest macro trader of all time?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Soros\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TvOQzOoO3kSD"
   },
   "outputs": [],
   "source": [
    "formatted_test_conversation = tokenizer.apply_chat_template(\n",
    "    conversation=test_conversation,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fyn2v9En7r-6",
    "outputId": "5607f0fe-0108-41db-8788-87d4c111d585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is the greatest macro trader of all time?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "George Soros<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(formatted_test_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGRnsVqfZDDJ"
   },
   "source": [
    "During inference, the user provides a question, and the LLM needs to generate the answer. To signal that itâ€™s the modelâ€™s turn to respond, we set `add_generation_prompt=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I9HHYbtE7jo5"
   },
   "outputs": [],
   "source": [
    "generation_conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is the greatest macro trader of all time?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yvAXVS9G7mK9"
   },
   "outputs": [],
   "source": [
    "formatted_gen_conversation = tokenizer.apply_chat_template(\n",
    "    conversation=generation_conversation,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2L5WL-Q7qTz",
    "outputId": "bf44d923-1397-4a70-e8db-187b0509d91b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is the greatest macro trader of all time?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_gen_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJqsAgdFZDDK"
   },
   "source": [
    "### Processing the dataset\n",
    "\n",
    "Next, we will format the entire dataset using the `.apply_chat_template` method.\n",
    "To do this, we define a helper function called `create_text_prompt`, which formats each example, and then apply it across the dataset using the `.map` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RcV1Ivtiz_Xd"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def create_text_prompt(example: Dict[str, str]) -> str:\n",
    "    conversation = [\n",
    "        {'role': 'user', \"content\": example['instruction'].strip()},\n",
    "        {'role': 'assistant', \"content\": example['output'].strip()},\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(conversation=conversation, tokenize=False, add_generation_prompt=False)\n",
    "    example[\"text\"] = text.strip()\n",
    "    return example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "72051a6ddaac4b9086a2a5009cc35a77",
      "05c61d87d8bd4bdcb10b728448107e31",
      "40c0c72ba46b4574ac9e29b7b30138df",
      "25b5671ee2df421eb7481b2cb24faeda",
      "f89590143b0b4f4d99ca752593b8f9ff",
      "4e305c9058a749eaa3bdf1dd39bb64c1",
      "ddbc47ede282491382a8b97f353ab944",
      "3b25abfbf96f4644b2af18fdca62d480",
      "5fe5268ec7b84312987e352469225df9",
      "d60e14b94bca498b9a53641a07e01ff8",
      "f2dd9838045740d1918c8d9eaf6e95b3"
     ]
    },
    "id": "uPPCL9fxlLV8",
    "outputId": "322b4e4b-252b-4720-a6c2-34b8200f5d5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72051a6ddaac4b9086a2a5009cc35a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/68912 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure we have a valid instruction and output pair\n",
    "data = data.filter(lambda x: len(x['instruction'].strip()) > 0 and len(x['output'].strip()) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq1fCmxMmFVB",
    "outputId": "0a25c1a1-64f9-4cc6-cd37-2ba58bd11252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68911"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "43b519cf8fae4f45939aaa2e7ec411a2",
      "b94abd72579449c3b1529f22be65409e",
      "5249faf91ca14a32b3d4ccf628f4d4f3",
      "c71d2a1253554849a3a7fc31b1c1fa54",
      "ccafacad0fef4426af12f5e75fe5726f",
      "241ebed69367443dbdd30894b0b77552",
      "5156c7bfd5ef474c9ea896339fb6c8a2",
      "c67c23b5771344f4a70c37decd880069",
      "68590edd5315476299bdfe4447101051",
      "4dceec4e857d4352800913ccc98504e3",
      "0014ff923de84c8c8112bba8a749ab3f"
     ]
    },
    "id": "qborlLKQ51kC",
    "outputId": "baf1a95d-6454-4534-ab95-dd7c36d66133"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b519cf8fae4f45939aaa2e7ec411a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data = data.map(create_text_prompt, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "km77fzXx57ZL",
    "outputId": "08ca1a2d-6e94-43bb-bebb-072db2323666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "For a car, what scams can be plotted with 0% financing vs rebate?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.<|eot_id|> \n",
      "\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why does it matter if a Central Bank has a negative rather than 0% interest rate?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.<|eot_id|> \n",
      "\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Where should I be investing my money?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Pay off your debt.  As you witnessed, no \"investment\" % is guaranteed.  But your debt payments are... so if you have cash, the best way to \"invest\" it is to pay off your debt.  Since your car is depreciating while your house may be appreciating (don't know but it's possible) you should pay off your car loan first.  You're losing money in more than one way on that investment.<|eot_id|> \n",
      "\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Specifically when do options expire?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Equity options, at least those traded in the American exchanges, actually expire the Saturday after the 3rd Friday of the month.  However, the choice to trade or exercise the options must be specified by the 3rd Friday. This is outlined by the CBOE, who oversees the exchange of equity options.  Their FAQ regarding option expiration can be found at http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.<|eot_id|> \n",
      "\n",
      "\n",
      "\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Negative Balance from Automatic Options Exercise. What to do?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Automatic exercisions can be extremely risky, and the closer to the money the options are, the riskier their exercisions are. It is unlikely that the entire account has negative equity since a responsible broker would forcibly close all positions and pursue the holder for the balance of the debt to reduce solvency risk.  Since the broker has automatically exercised a near the money option, it's solvency policy is already risky. Regardless of whether there is negative equity or simply a liability, the least risky course of action is to sell enough of the underlying to satisfy the loan by closing all other positions if necessary as soon as possible. If there is a negative equity after trying to satisfy the loan, the account will need to be funded for the balance of the loan to pay for purchases of the underlying to fully satisfy the loan. Since the underlying can move in such a way to cause this loan to increase, the account should also be funded as soon as possible if necessary. Accounts after exercise For deep in the money exercised options, a call turns into a long underlying on margin while a put turns into a short underlying. The next decision should be based upon risk and position selection.  First, if the position is no longer attractive, it should be closed.  Since it's deep in the money, simply closing out the exposure to the underlying should extinguish the liability as cash is not marginable, so the cash received from the closing out of the position will repay any margin debt. If the position in the underlying is still attractive then the liability should be managed according to one's liability policy and of course to margin limits. In a margin account, closing the underlying positions on the same day as the exercise will only be considered a day trade.  If the positions are closed on any business day after the exercision, there will be no penalty or restriction. Cash option accounts While this is possible, many brokers force an upgrade to a margin account, and the ShareBuilder Options Account Agreement seems ambiguous, but their options trading page implies the upgrade. In a cash account, equities are not marginable, so any margin will trigger a margin call.  If the margin debt did not trigger a margin call then it is unlikely that it is a cash account as margin for any security in a cash account except for certain options trades is 100%. Equities are convertible to cash presumably at the bid, so during a call exercise, the exercisor or exercisor's broker pays cash for the underlying at the exercise price, and any deficit is financed with debt, thus underlying can be sold to satisfy that debt or be sold for cash as one normally would. To preempt a forced exercise as a call holder, one could short the underlying, but this will be more expensive, and since probably no broker allows shorting against the box because of its intended use to circumvent capital gains taxes by fraud.  The least expensive way to trade out of options positions is to close them themselves rather than take delivery.<|eot_id|> \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    item = processed_data[i]\n",
    "    print(item['text'], '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgE13V4LZDDK"
   },
   "source": [
    "## Parameter Efficient FineTuning (PEFT)\n",
    "\n",
    "Our model has **8 billion parameters**, and fine-tuning all of them would be extremely slow, memory-intensive, and it comes with risk of catastrophic forgetting.\n",
    "\n",
    "To solve this, we use **LoRA** (Low-Rank Adaptation), a technique that allows us to fine-tune only a small number of additional parameters on top of the original model parameters.\n",
    "\n",
    "LoRA works by injecting small trainable \"adapters\" into certain parts of the model (such as the attention layers). This makes fine-tuning much faster, requires far less memory, and lets us achieve high-quality results without needing to update billions of parameters. To learn more about Parameter Efficient Fine-Tuning (PEFT), refer to Chapter 10 of the book.\n",
    "\n",
    "In the next step, we will set up LoRA for our Llama 3.1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBBnIQsJZDDL",
    "outputId": "e290cd37-c4be-4a63-c2fe-cccda6d39e6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    # Rank of the LoRA matrices â€” controls the number of trainable parameters (suggested: 8, 16, 32, 64, or 128)\n",
    "    r = 16,\n",
    "    # Layers where LoRA adapters will be injected (mostly attention and MLP layers)\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention projections\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",     # Feed-forward (MLP) projections\n",
    "    ],\n",
    "    # Scaling factor for the LoRA updates â€” balances the impact of the new weights\n",
    "    lora_alpha = 16,\n",
    "    # Dropout rate for LoRA layers â€” 0 means no dropout (good for small/medium datasets)\n",
    "    lora_dropout = 0,\n",
    "    # Whether to fine-tune bias terms â€” \"none\" skips bias for faster, more memory-efficient training\n",
    "    bias = \"none\",\n",
    "    # Enables memory-saving checkpointing (\"unsloth\" version is highly optimized)\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    # Random seed to make training reproducible\n",
    "    random_state = 3407,\n",
    "    # Whether to use Rank-Stabilized LoRA (RSLoRA) â€” standard LoRA is used here\n",
    "    use_rslora = False,\n",
    "    # Configuration for LoftQ (LoRA + Quantization) â€” not used here\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSIc9RYRZDDL"
   },
   "source": [
    "## Training\n",
    "\n",
    "Now that our model is prepared, we are ready to start the fine-tuning process!  \n",
    "\n",
    "The training procedure is very similar to standard supervised fine-tuning of any Transformer model.\n",
    "\n",
    "We will first define our training hyperparameters using `TrainingArguments`, and then use the `SFTTrainer` from the `trl` library to handle the training loop for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m80eMmMCorLp"
   },
   "outputs": [],
   "source": [
    "train_test_split = processed_data.train_test_split(test_size=0.2, seed=3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c95b1c8425d8463f9394937883b874e5",
      "594b075f1119461cb0f4d4eb7630daeb",
      "82838a742758411098623ae60a5ed80a",
      "744e06bef6f148459392d31b866f9e72",
      "2dc790e7890a4a659450bd0d8dba93e0",
      "0cebe8a3839844c2892cf20674e19a75",
      "f9fa2d9d282b493da791639fe3d3d61d",
      "7d4722a1cccc45cfb3bfa7d713912766",
      "b56af5ac44654b2d810b337415cb2fec",
      "3e5b3dacf9f14e06adccbf6cd151ce79",
      "50b1fa48d95748fba041c948445c1037"
     ]
    },
    "id": "6f9wlXrO8Jrf",
    "outputId": "2b8d0f83-1a2f-4b49-c0e2-06cb0d9b91b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95b1c8425d8463f9394937883b874e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/55128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=5,\n",
    "        max_steps=60,\n",
    "        learning_rate=5e-6,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"output\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_test_split['train'],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MODEL_CONFIG['max_seq_length'],\n",
    "    dataset_num_proc=2,\n",
    "    packing=False, # Can make training 5x faster for short sequences.\n",
    "    args=training_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-BOEjoWn8rpH",
    "outputId": "06069f08-0fa8-437f-ce6f-edc401c3d288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 55,128 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 06:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.860700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.721900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.770700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.827600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.079100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.701400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.144200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.849200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.835400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.542500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.806200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.343700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.343700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.886100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.480700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.975600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.328500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.834600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.130700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.059200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3JerMzX82oe"
   },
   "source": [
    "## Text Generation\n",
    "\n",
    "Now that our model has been trained, it's time to generate some text!\n",
    "To generate a response, we need to:\n",
    "\n",
    "1. Apply the chat template to the user's query.\n",
    "2. Tokenize into their token ids.\n",
    "3. Generate a response based on the input.\n",
    "4. Detokenize the generated response back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3uGU4YS_Cpaq"
   },
   "outputs": [],
   "source": [
    "def create_completion_inputs(content: str) -> torch.Tensor:\n",
    "    conversation = [{\"role\": \"user\", \"content\": content}]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Np-CsLe7ZDDL"
   },
   "outputs": [],
   "source": [
    "input_ids = create_completion_inputs(\"What is the time value of options?\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rp3S4P1vDR8H",
    "outputId": "0737a533-b8cd-412f-b59d-e43966dfe564"
   },
   "source": [
    "the input_ids have shape (n_sentences, n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf-w08ByZDDL",
    "outputId": "88675b0d-b7ea-4d9c-86f2-3cd3ca7d9fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 43])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKwgUduTLGyR",
    "outputId": "e41eeeee-5186-442b-c03a-fe8a8cb2f95e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
       "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
       "            220,   1627,  10263,    220,   2366,     19,    271, 128009, 128006,\n",
       "            882, 128007,    271,   3923,    374,    279,    892,    907,    315,\n",
       "           2671,     30, 128009, 128006,  78191, 128007,    271]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGrQQFt2plJY",
    "outputId": "10c122e3-8b32-4371-fcb0-323075d75368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the time value of options?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO9OE6AYDVgr",
    "outputId": "8a102d7e-98f9-41c1-cb17-719f9b797574"
   },
   "source": [
    "using the `.generate` method, which will continue generating tokens until either the end-of-sequence (EOS) token is reached or the maximum number of new tokens (max_new_tokens) is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo0qpnsM1cHD",
    "outputId": "635013db-d173-42a4-d222-077ddcbf60d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=256,\n",
    "    use_cache=True,\n",
    "    eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVCkIY5PDiwZ"
   },
   "source": [
    "The output_ids will contain both the input tokens and the generated completion tokens, so we will remove the part that belongs to the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2MoAlVtZDDL",
    "outputId": "5274ba28-d65a-4b17-fe68-869f0e49a6a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  791,  4212,  5273,   315, 14908,   320,    51, 11417,     8,   374,\n",
       "          264,  7434,   304, 17452,   430, 19813,   311,   279,   907,   315,\n",
       "          279,  3072,   311,   279, 12102,   520,   904,  2728,   892,    13,\n",
       "         1102,   374,   279,  6811,  1990,   279,  3072,   596,   907,   520,\n",
       "          279,   892,   315,  7782,   323,  1202,   907,   520, 32792,   382,\n",
       "          644,  1023,  4339,    11,   279,  4212,  5273,   315, 14908,   374,\n",
       "          279, 15193,   430,   459,  3072, 26171, 21935,   369,   279,  3072,\n",
       "          311,   387, 62113,   520,   264,  3938,  2457,    13,  1102,   374,\n",
       "          279,   907,   430,   279,  3072,   706,  4245,   311,   279,   892,\n",
       "          430,  8625,  1603,   433, 29002,   382,   791,  4212,  5273,   315,\n",
       "        14908,   374, 11383,  8592,   369,  2671,   430,   527,   304,   279,\n",
       "         3300,   320,    72,  1770,  2637,   279, 16940,  9513,   596,  3430,\n",
       "          374,  3485,   279, 13471,  3430,   369,   264,  1650,  3072,   477,\n",
       "         3770,   279, 13471,  3430,   369,   264,  2231,  3072,     8,   323,\n",
       "        15821,   369,  2671,   430,   527,   520,   279,  3300,   320,    72,\n",
       "         1770,  2637,   279, 16940,  9513,   596,  3430,   374,  6273,   311,\n",
       "          279, 13471,  3430,  3677,   791,  4212,  5273,   315, 14908,   649,\n",
       "          387, 11754,   555,  3892,  9547,    11,  2737,  1473,    16,    13,\n",
       "          578, 16940,  9513,   596,  3430,    25,  1442,   279, 16940,  9513,\n",
       "          596,  3430,   374, 17509,    11,   279,  4212,  5273,   315, 14908,\n",
       "          690,   387,  5190,   627,    17,    13,   578,   892,   311, 32792,\n",
       "           25,   578,  4212,  5273,   315, 14908,   374, 11383,  8592,   369,\n",
       "         2671,   430,   527,  3345,   311, 32792,   323, 15821,   369,  2671,\n",
       "          430,   527,  3117,   505, 32792,   627,    18,    13,   578,  3072,\n",
       "          596, 13471,  3430,    25,  1442,   279,  3072,   596, 13471,  3430,\n",
       "          374,  3345,   311,   279, 16940,  9513])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completions = output_ids[:, input_ids.shape[1]:].cpu()[0]\n",
    "completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj9xBhCCZDDL"
   },
   "source": [
    "Now we can decode the tokens into text using the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "I7i_2FEEDmV3"
   },
   "outputs": [],
   "source": [
    "completion_text = tokenizer.decode(completions, skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5R215nuZDDL",
    "outputId": "df826748-af24-43d2-c1b7-045120bea16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Value of Options (TVO) is a concept in finance that refers to the value of the option to the holder at any given time. It is the difference between the option's value at the time of purchase and its value at expiration.\n",
      "\n",
      "In other words, the Time Value of Options is the premium that an option buyer pays for the option to be exercised at a future date. It is the value that the option has due to the time that remains before it expires.\n",
      "\n",
      "The Time Value of Options is typically highest for options that are in the money (i.e., the underlying asset's price is above the strike price for a call option or below the strike price for a put option) and lowest for options that are at the money (i.e., the underlying asset's price is equal to the strike price).\n",
      "\n",
      "The Time Value of Options can be affected by several factors, including:\n",
      "\n",
      "1. The underlying asset's price: If the underlying asset's price is volatile, the Time Value of Options will be higher.\n",
      "2. The time to expiration: The Time Value of Options is typically highest for options that are close to expiration and lowest for options that are far from expiration.\n",
      "3. The option's strike price: If the option's strike price is close to the underlying asset\n"
     ]
    }
   ],
   "source": [
    "print(completion_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXKc1Qn_ZDDL"
   },
   "source": [
    "Feel free to experiment with the model and ask it more complex finance-related questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mykNfsEh1Jht"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
